# PyVR: Python Volume Rendering Toolkit

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: WTFPL](https://img.shields.io/badge/License-WTFPL-brightgreen.svg)](http://www.wtfpl.net/about/)
![Version](https://img.shields.io/badge/version-0.2.4-blue.svg)
[![Tests](https://img.shields.io/badge/tests-162%20passing-brightgreen.svg)](#-testing)

PyVR is a GPU-accelerated 3D volume rendering toolkit for real-time interactive visualization using OpenGL. Built with ModernGL, it provides high-performance volume rendering with a modern, modular architecture.

> âš ï¸ **Pre-1.0 Development**: Breaking changes are expected. API stability comes at v1.0.0.

## ğŸ¯ Key Features

- **âš¡ GPU-Accelerated Rendering**: Real-time OpenGL volume rendering via ModernGL at 64+ FPS
- **ğŸš€ High-Performance RGBA Textures**: Single-texture transfer function lookups for optimal performance
- **ğŸ§© Pipeline-Aligned Architecture**: Clean separation of Application, Geometry, and Fragment stages
- **ğŸ“¹ Advanced Camera System**: Matrix generation, spherical coordinates, animation paths, and presets
- **ğŸ’¡ Flexible Lighting System**: Directional, point, and ambient light presets with easy configuration
- **ğŸ¨ Sophisticated Transfer Functions**: Color and opacity mappings with matplotlib integration
- **ğŸ“Š Synthetic Datasets**: Built-in generators for testing and development
- **âœ… Comprehensive Testing**: 162 tests with 95%+ coverage

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/JixianLi/pyvr.git
cd pyvr

# Install with Poetry (recommended)
poetry install

# Or install dependencies manually
pip install moderngl numpy matplotlib pillow scipy
```

### Basic Usage

```python
import numpy as np
import matplotlib.pyplot as plt
from pyvr.moderngl_renderer import VolumeRenderer
from pyvr.transferfunctions import ColorTransferFunction, OpacityTransferFunction
from pyvr.camera import Camera
from pyvr.lighting import Light
from pyvr.datasets import create_sample_volume, compute_normal_volume

# Create volume data
volume = create_sample_volume(256, 'double_sphere')
normals = compute_normal_volume(volume)

# Create camera
camera = Camera.from_spherical(
    target=np.array([0.0, 0.0, 0.0]),
    distance=3.0,
    azimuth=np.pi/4,      # 45 degrees
    elevation=np.pi/6,    # 30 degrees
    roll=0.0
)

# Create light
light = Light.directional(direction=[1, -1, 0], ambient=0.2, diffuse=0.8)

# Create renderer
renderer = VolumeRenderer(width=512, height=512, light=light)
renderer.load_volume(volume)
renderer.load_normal_volume(normals)
renderer.set_volume_bounds((-1.0, -1.0, -1.0), (1.0, 1.0, 1.0))
renderer.set_camera(camera)

# Set up transfer functions
ctf = ColorTransferFunction.from_colormap('viridis')
otf = OpacityTransferFunction.linear(0.0, 0.1)
renderer.set_transfer_functions(ctf, otf)

# Render
data = renderer.render()
image = np.frombuffer(data, dtype=np.uint8).reshape((512, 512, 4))

plt.imshow(image, origin='lower')
plt.show()
```

## ğŸ—ï¸ Architecture

PyVR follows a pipeline-aligned architecture based on traditional rendering pipeline stages:

```
pyvr/
â”œâ”€â”€ camera/               # Geometry Stage - Camera transformations
â”‚   â”œâ”€â”€ parameters.py     # Camera class with matrix generation
â”‚   â””â”€â”€ control.py        # Camera controllers and animation
â”œâ”€â”€ lighting/             # Application Stage - Light configuration
â”‚   â””â”€â”€ light.py          # Light class with presets
â”œâ”€â”€ transferfunctions/    # Application Stage - Material properties
â”‚   â”œâ”€â”€ color.py          # Color transfer functions
â”‚   â””â”€â”€ opacity.py        # Opacity transfer functions
â”œâ”€â”€ shaders/              # Fragment Stage - Shading operations
â”‚   â”œâ”€â”€ volume.vert.glsl  # Vertex shader
â”‚   â””â”€â”€ volume.frag.glsl  # Fragment shader with RGBA lookups
â”œâ”€â”€ datasets/             # Application Stage - Volume data
â”‚   â””â”€â”€ synthetic.py      # Synthetic volume generators
â””â”€â”€ moderngl_renderer/    # Rendering orchestration (OpenGL backend)
    â”œâ”€â”€ renderer.py       # High-level volume renderer
    â””â”€â”€ manager.py        # Low-level OpenGL resource management
```

## ğŸ“Š Synthetic Datasets

PyVR includes built-in synthetic volume generators:

```python
from pyvr.datasets import create_sample_volume, compute_normal_volume

# Create various synthetic volumes
sphere = create_sample_volume(256, 'sphere')
torus = create_sample_volume(256, 'torus')
double_sphere = create_sample_volume(256, 'double_sphere')
helix = create_sample_volume(256, 'helix')
cube = create_sample_volume(256, 'cube')
blob = create_sample_volume(256, 'random_blob')

# Compute normal vectors for lighting
normals = compute_normal_volume(sphere)
```

## ğŸ¨ Transfer Functions

### Color Transfer Functions

```python
from pyvr.transferfunctions import ColorTransferFunction

# From matplotlib colormaps
ctf = ColorTransferFunction.from_colormap('viridis')
ctf = ColorTransferFunction.from_colormap('plasma', value_range=(0.2, 0.8))

# Custom control points
ctf = ColorTransferFunction(control_points=[
    (0.0, [0.0, 0.0, 1.0]),  # Blue at low values
    (0.5, [0.0, 1.0, 0.0]),  # Green at mid values
    (1.0, [1.0, 0.0, 0.0])   # Red at high values
])

# Convenience methods
ctf = ColorTransferFunction.grayscale(intensity=0.8)
ctf = ColorTransferFunction.single_color([1.0, 0.5, 0.0])
```

### Opacity Transfer Functions

```python
from pyvr.transferfunctions import OpacityTransferFunction

# Linear opacity ramp
otf = OpacityTransferFunction.linear(min_opacity=0.0, max_opacity=0.5)

# Step function
otf = OpacityTransferFunction.step(threshold=0.3, low_opacity=0.0, high_opacity=1.0)

# Multiple peaks
otf = OpacityTransferFunction.peaks(
    peaks=[0.3, 0.7],
    opacity=0.8,
    eps=0.1
)

# Custom control points
otf = OpacityTransferFunction(control_points=[
    (0.0, 0.0),
    (0.2, 0.1),
    (0.5, 0.8),  # Peak
    (0.8, 0.2),
    (1.0, 0.0)
])
```

## ğŸ“¹ Camera System

### Camera Creation and Control

```python
from pyvr.camera import Camera, CameraController, CameraPath
import numpy as np

# Create camera with spherical coordinates
camera = Camera.from_spherical(
    target=np.array([0.0, 0.0, 0.0]),
    distance=5.0,
    azimuth=np.pi/4,      # 45Â° horizontal
    elevation=np.pi/6,    # 30Â° vertical
    roll=0.0
)

# Use preset views
camera = Camera.front_view(distance=3.0)
camera = Camera.side_view(distance=3.0)
camera = Camera.top_view(distance=3.0)
camera = Camera.isometric_view(distance=4.0)

# Camera generates transformation matrices
view_matrix = camera.get_view_matrix()
projection_matrix = camera.get_projection_matrix(aspect_ratio=16/9)
position, up = camera.get_camera_vectors()

# Set camera in renderer
renderer.set_camera(camera)
```

### Camera Animation

```python
# Create smooth camera paths
cameras = [
    Camera.front_view(distance=3.0),
    Camera.isometric_view(distance=3.0),
    Camera.side_view(distance=3.0)
]
path = CameraPath(keyframes=cameras)

# Interpolate between keyframes
interpolated_camera = path.interpolate(t=0.5)  # Halfway

# Generate animation frames
frames = path.generate_frames(n_frames=30)

# Interactive camera controller
controller = CameraController(initial_params=camera)
controller.orbit(delta_azimuth=0.1, delta_elevation=0.05)
controller.zoom(factor=1.1)
controller.pan(delta=np.array([0.1, 0, 0]))
controller.roll_camera(delta_roll=0.1)
```

## ğŸ’¡ Lighting System

### Light Creation

```python
from pyvr.lighting import Light

# Directional light (like sunlight)
light = Light.directional(
    direction=[1, -1, 0],  # Normalized automatically
    ambient=0.2,           # Ambient intensity (0.0-1.0)
    diffuse=0.8            # Diffuse intensity (0.0-1.0)
)

# Point light at specific position
light = Light.point_light(
    position=[5, 5, 5],
    target=[0, 0, 0],
    ambient=0.1,
    diffuse=0.7
)

# Ambient-only lighting (no directional component)
light = Light.ambient_only(intensity=0.5)

# Default light
light = Light.default()
```

### Using Lights with Renderer

```python
# Pass light to renderer constructor
light = Light.directional(direction=[1, -1, 0], ambient=0.3)
renderer = VolumeRenderer(width=512, height=512, light=light)

# Or set/update later
light = Light.point_light(position=[5, 5, 5])
renderer.set_light(light)

# Get current light
current_light = renderer.get_light()

# Access light properties
direction = light.get_direction()
print(f"Position: {light.position}")
print(f"Ambient: {light.ambient_intensity}")
print(f"Diffuse: {light.diffuse_intensity}")

# Copy and modify
new_light = light.copy()
new_light.ambient_intensity = 0.5
```

## ğŸ“¸ Examples

The `example/ModernglRender/` directory contains complete working examples:

- **`rgba_demo.py`**: RGBA transfer function demonstration
- **`enhanced_camera_demo.py`**: Advanced camera system with presets and paths
- **`multiview_example.py`**: Multi-view rendering example

Run examples:
```bash
python example/ModernglRender/rgba_demo.py
python example/ModernglRender/enhanced_camera_demo.py
python example/ModernglRender/multiview_example.py
```

## âš¡ Performance

- **Rendering Performance**: 64+ FPS at 512Ã—512 resolution (15.6ms avg render time)
- **Pixel Throughput**: 16.8+ MPix/s on modern GPUs
- **Memory Efficiency**: Single RGBA texture lookup vs dual RGB+Alpha operations
- **Scalability**: Real-time for volumes up to 512Â³ voxels on modern hardware

### Performance Tuning

**High Quality** (slower):
```python
renderer = VolumeRenderer(1024, 1024, step_size=0.001, max_steps=1000)
```

**Balanced**:
```python
renderer = VolumeRenderer(512, 512, step_size=0.01, max_steps=500)
```

**High Performance** (faster):
```python
renderer = VolumeRenderer(256, 256, step_size=0.02, max_steps=100)
```

## ğŸ§ª Testing

PyVR has comprehensive test coverage for reliability:

```bash
# Run all tests (162 tests)
pytest tests/

# Run with coverage report
pytest --cov=pyvr --cov-report=term-missing tests/

# Run specific test modules
pytest tests/test_camera/              # Camera system tests (42 tests)
pytest tests/test_lighting/            # Lighting tests (22 tests)
pytest tests/test_moderngl_renderer/   # Renderer tests (36 tests)
pytest tests/test_transferfunctions/   # Transfer function tests (30 tests)
```

**Test Coverage Breakdown:**
```
Module                        Tests    Coverage
----------------------------------------------
ğŸ“· Camera System              42       95%
ğŸ’¡ Lighting System            22       95%
ğŸ¨ Transfer Functions         30       94-100%
ğŸ–¥ï¸  ModernGL Renderer         36       93-100%
ğŸ“Š Datasets & Utilities       32       Various
----------------------------------------------
ğŸ“ˆ Total                     162       ~90%
```

## ğŸ› ï¸ API Reference

### Volume Rendering Pipeline

```python
from pyvr.moderngl_renderer import VolumeRenderer
from pyvr.camera import Camera
from pyvr.lighting import Light
from pyvr.transferfunctions import ColorTransferFunction, OpacityTransferFunction
from pyvr.datasets import create_sample_volume, compute_normal_volume
import numpy as np

# Create camera
camera = Camera.from_spherical(
    target=np.array([0, 0, 0]),
    distance=5.0,
    azimuth=np.pi/4,
    elevation=np.pi/6,
    roll=0.0
)

# Create light
light = Light.directional(direction=[1, -1, 0], ambient=0.2, diffuse=0.8)

# Create renderer
renderer = VolumeRenderer(width=512, height=512, light=light)
renderer.set_camera(camera)

# Load volume data
volume = create_sample_volume(256, 'double_sphere')
normals = compute_normal_volume(volume)
renderer.load_volume(volume)
renderer.load_normal_volume(normals)
renderer.set_volume_bounds((-1, -1, -1), (1, 1, 1))

# Configure transfer functions
ctf = ColorTransferFunction.from_colormap('viridis')
otf = OpacityTransferFunction.linear(0.0, 0.1)
renderer.set_transfer_functions(ctf, otf)

# Render
data = renderer.render()

# Camera operations
view_matrix = camera.get_view_matrix()
projection_matrix = camera.get_projection_matrix(aspect_ratio=16/9)

# Camera animation
from pyvr.camera import CameraController, CameraPath
controller = CameraController(camera)
controller.orbit(delta_azimuth=0.1, delta_elevation=0.05)
path = CameraPath(keyframes=[camera1, camera2])
frames = path.generate_frames(30)
```

## ğŸ“‹ Requirements

- **Python**: 3.11+
- **Core Dependencies**:
  - NumPy >= 2.3
  - Matplotlib >= 3.10
  - Pillow >= 11.0
  - SciPy >= 1.16
- **OpenGL Backend**:
  - ModernGL >= 5.0

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes and add tests
4. Ensure all tests pass (`poetry run pytest`)
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Development Setup

```bash
# Clone and install in development mode
git clone https://github.com/JixianLi/pyvr.git
cd pyvr
poetry install --with dev

# Run tests
poetry run pytest

# Format code
poetry run black pyvr/
poetry run isort pyvr/
```

## ğŸ“„ License

This project is licensed under the WTFPL (Do What The F*ck You Want To Public License) - see the [LICENSE](LICENSE) file for details.

## ğŸ™‹ Support

- **Issues**: [GitHub Issues](https://github.com/JixianLi/pyvr/issues)
- **Email**: jixianli@sci.utah.edu
- **Version Notes**: See `version_notes/` directory for detailed release information

## ğŸ† Acknowledgments

- Claude Sonnet 4 model from GitHub Copilot for the creation of almost all code/documentation/test in this repository (some code was created by Claude Sonnet 3.5) <-- I wrote this sentence. That's about it for my contribution to this repo
- ModernGL community for excellent OpenGL bindings
- The scientific visualization community

---

**PyVR** - High-performance OpenGL volume rendering for real-time interactive visualization! ğŸš€
